{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367273de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e096a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:57:40.461926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827bc237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zacharyg/opt/anaconda3/envs/research/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2f697",
   "metadata": {},
   "source": [
    "# Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c0b82",
   "metadata": {},
   "source": [
    "```\n",
    "1 - 2          1     \n",
    "|   |         /  \\       1 - 2\n",
    "3 - 4        2 -- 3   \n",
    "```\n",
    "\n",
    "There are the type of graphs made for our GNN.\n",
    "Each node will contain a pandas data frame where the features are:\n",
    "\n",
    "```\n",
    "a b c\n",
    "- - - \n",
    "G C ? \n",
    "```\n",
    "Where G is given and C is calculated. Feature B is calculated by taking feature a's of its neighbors. C is calulcuated by (a + b) in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ebed5",
   "metadata": {},
   "source": [
    "Here are adjacency matrix is (respectively):\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 1 & 0\\\\\n",
    "1 & 0 & 0 & 1\\\\\n",
    "1 & 0 & 0 & 1\\\\\n",
    "0 & 1 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 1\\\\\n",
    "1 & 0 & 1\\\\\n",
    "1 & 1 & 0\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c678616",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1A = np.array([[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1],[0, 1, 1, 0]])\n",
    "G2A = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
    "G3A = np.array([[0, 1,], [1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a00e32",
   "metadata": {},
   "source": [
    "For the respective graphs:\n",
    "```\n",
    "1:     2:     3:     4:\n",
    "a b c  a b c  a b c  a b c\n",
    "- - -  - - -  - - -  - - -\n",
    "2 5 7  3 3 6  2 3 5  1 5 6\n",
    "\n",
    "1:      2:      3:     \n",
    "a b c   a b c   a b c  \n",
    "- - -   - - -   - - - \n",
    "4 7 11  5 6 11  2 9 11 \n",
    "\n",
    "1:     2:   \n",
    "a b c  a b c \n",
    "- - -  - - - \n",
    "2 1 3  1 2 3  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a095e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_1 = {\n",
    "    \"a\": [2],\n",
    "    \"b\": [5],\n",
    "    \"c\": [7],\n",
    "}\n",
    "\n",
    "G1_2 = {\n",
    "    \"a\": [3],\n",
    "    \"b\": [3],\n",
    "    \"c\": [6],\n",
    "}\n",
    "\n",
    "G1_3 = {\n",
    "    \"a\": [2],\n",
    "    \"b\": [3],\n",
    "    \"c\": [5],\n",
    "}\n",
    "\n",
    "G1_4 = {\n",
    "    \"a\": [1],\n",
    "    \"b\": [5],\n",
    "    \"c\": [6],\n",
    "}\n",
    "\n",
    "G2_1 = {\n",
    "    \"a\": [4],\n",
    "    \"b\": [7],\n",
    "    \"c\": [11],\n",
    "}\n",
    "\n",
    "G2_2 = {\n",
    "    \"a\": [5],\n",
    "    \"b\": [6],\n",
    "    \"c\": [11],\n",
    "}\n",
    "\n",
    "G2_3 = {\n",
    "    \"a\": [2],\n",
    "    \"b\": [9],\n",
    "    \"c\": [11],\n",
    "}\n",
    "\n",
    "G3_1 = {\n",
    "    \"a\": [2],\n",
    "    \"b\": [1],\n",
    "    \"c\": [3],\n",
    "}\n",
    "\n",
    "G3_2 = {\n",
    "    \"a\": [1],\n",
    "    \"b\": [2],\n",
    "    \"c\": [3],\n",
    "}\n",
    "\n",
    "data = [G1_1, G1_2, G1_3, G1_4, G2_1, G2_2, G2_3, G3_1, G3_2]\n",
    "dfs = []\n",
    "\n",
    "for dataframe in data:\n",
    "    df = pd.DataFrame(dataframe)\n",
    "    dfs.append(df)\n",
    "    \n",
    "dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0bdce",
   "metadata": {},
   "source": [
    "# Building the dataset [Normal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adjacency(adjacency_matrix):\n",
    "    degrees = np.sum(adjacency_matrix, axis=1)\n",
    "    D_inv_sqrt = np.diag(np.power(degrees, -0.5))\n",
    "    normalized_adjacency = np.dot(np.dot(D_inv_sqrt, adjacency_matrix), D_inv_sqrt)\n",
    "    return normalized_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a97568",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1A_list = [np.float32(normalize_adjacency(G1A)) for i in range(1000)]\n",
    "G2A_list = [np.float32(normalize_adjacency(G1A)) for i in range(1000)]\n",
    "G3A_list = [np.float32(normalize_adjacency(G1A)) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_list = G1A_list + G2A_list + G3A_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(A_list))\n",
    "# print(A_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e87fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_F = np.concatenate((\n",
    "    np.float32(dfs[0].drop(columns=[\"b\"]).to_numpy()), \n",
    "    np.float32(dfs[1].drop(columns=[\"b\"]).to_numpy()), \n",
    "    np.float32(dfs[2].drop(columns=[\"b\"]).to_numpy()), \n",
    "    np.float32(dfs[3].drop(columns=[\"b\"]).to_numpy())\n",
    "))\n",
    "\n",
    "G2_F = np.concatenate((\n",
    "    np.float32(dfs[4].drop(columns=[\"b\"]).to_numpy()), \n",
    "    np.float32(dfs[5].drop(columns=[\"b\"]).to_numpy()), \n",
    "    np.float32(dfs[6].drop(columns=[\"b\"]).to_numpy())\n",
    "))\n",
    "\n",
    "G3_F = np.concatenate((\n",
    "    np.float32(dfs[7].drop(columns=[\"b\"]).to_numpy()), \n",
    "   np.float32( dfs[8].drop(columns=[\"b\"]).to_numpy())\n",
    ")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0726cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_F_list = [G1_F for i in range(1000)]\n",
    "G2_F_list = [G2_F for i in range(1000)]\n",
    "G3_F_list = [G3_F for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = G1_F_list + G2_F_list + G3_F_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_list))\n",
    "# print(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27116e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_y = np.concatenate((\n",
    "    dfs[0].drop(columns=[\"a\", \"c\"]).to_numpy(), \n",
    "    dfs[1].drop(columns=[\"a\", \"c\"]).to_numpy(), \n",
    "    dfs[2].drop(columns=[\"a\", \"c\"]).to_numpy(), \n",
    "    dfs[3].drop(columns=[\"a\", \"c\"]).to_numpy()\n",
    "))\n",
    "\n",
    "G2_y = np.concatenate((\n",
    "    dfs[4].drop(columns=[\"a\", \"c\"]).to_numpy(), \n",
    "    dfs[5].drop(columns=[\"a\", \"c\"]).to_numpy(), \n",
    "    dfs[6].drop(columns=[\"a\", \"c\"]).to_numpy()\n",
    "))\n",
    "\n",
    "G3_y = np.concatenate((\n",
    "    dfs[7].drop(columns=[\"a\", \"c\"]).to_numpy(), \n",
    "    dfs[8].drop(columns=[\"a\", \"c\"]).to_numpy()\n",
    ")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_y_list = [np.float32(G1_y) for i in range(1000)]\n",
    "G2_y_list = [np.float32(G2_y) for i in range(1000)]\n",
    "G3_y_list = [np.float32(G3_y) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = G1_y_list + G2_y_list + G3_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ca693",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_list))\n",
    "# print(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d18d2c",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85166cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "    A_list, \n",
    "    X_list, \n",
    "    y_list, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad47e73",
   "metadata": {},
   "source": [
    "# Building Dataset [Torch Geometric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ca6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d949e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd985fa7",
   "metadata": {},
   "source": [
    "# Graph Neural Network [Torch Geometric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bed62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b967f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_convolution_layer(adjacency, input_features, output_dim, activation):\n",
    "    transformed_features = tf.matmul(tf.matmul(adjacency, input_features),\n",
    "                                     tf.Variable(tf.random.normal(shape=(input_features.shape[1], output_dim))))\n",
    "    return activation(transformed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_convolution_model():\n",
    "    input_adjacency = tf.keras.Input(shape=(None, None), dtype=tf.float32, name=\"adjacency\")\n",
    "    input_features = tf.keras.Input(shape=(None, 1), dtype=tf.float32, name=\"features\")\n",
    "    \n",
    "    gnn_layer = GraphConvolutionLayer(units=16)\n",
    "    hidden_layer = tf.keras.layers.Dense(32, activation=\"relu\")(gnn_layer([input_adjacency, input_features]))\n",
    "    output_layer = tf.keras.layers.Dense(1, activation=\"linear\")  # Each node predicts one feature\n",
    "    \n",
    "    output = output_layer(hidden_layer)\n",
    "    \n",
    "    gnn_model = Model(inputs=[input_adjacency, input_features], outputs=output)\n",
    "    gnn_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    \n",
    "    return gnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "batch_size = 1\n",
    "\n",
    "gnn_model = graph_convolution_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    # Mini-batch training\n",
    "    indices = np.arange(len(X_train))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        batch_indices = indices[start : start + batch_size]\n",
    "        batch_A = [A_train[i] for i in batch_indices]\n",
    "        batch_X = [X_train[i] for i in batch_indices]\n",
    "        batch_y = [y_train[i] for i in batch_indices]\n",
    "        \n",
    "        loss = gnn_model.train_on_batch([batch_A, batch_X], batch_y)\n",
    "        print(f\"  Batch Loss: {loss}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss = gnn_model.evaluate([A_test, X_test], y_test, verbose=0)\n",
    "    print(f\"  Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15052b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f852a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c021f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
