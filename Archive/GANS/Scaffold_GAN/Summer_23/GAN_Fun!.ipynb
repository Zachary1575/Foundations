{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import randint\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c38f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Reshape\n",
    "from keras import backend\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12c929",
   "metadata": {},
   "source": [
    "# Generate a Distribution (Normal Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea30e1",
   "metadata": {},
   "source": [
    "Remember that the guassian curve:\n",
    "\n",
    "$$g(x) = \\dfrac{1}{\\sigma \\sqrt{2 \\pi}} \\ exp \\left(-\\dfrac{1}{2} \\dfrac{(x - \\mu)^2}{\\sigma^2} \\right) $$\n",
    "\n",
    "(***Note exp(x) is equivalent to $e^x$)\n",
    "\n",
    "such that: \n",
    "\n",
    "$\\sigma =$ standard deviation \n",
    "\n",
    "$\\mu =$ mean\n",
    "\n",
    "For our application, let $\\sigma =$ 1 and $\\mu =$ 5. While the domain of $x \\in [0, 10]$. This simplfies to:\n",
    "\n",
    "$$g(x) = \\dfrac{1}{\\sqrt{2 \\pi}} \\ exp \\left(-\\dfrac{1}{2} (x - 5)^2 \\right) $$\n",
    "\n",
    "We will use the distrbution as our data and see how a GAN matches these points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446864f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGuassianDistributionPoints(\n",
    "    sigma=1, \n",
    "    mu=5,\n",
    "    interval=[0, 10],\n",
    "    points=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Guassian Distribution function. Note that mu and sigma are NOT protected. So have a mean past the interval\n",
    "    will break the function.\n",
    "    \"\"\"\n",
    "    y_data = [];\n",
    "    x_data = [];\n",
    "    distance = abs(interval[0]) + abs(interval[1]);\n",
    "    step = float(distance) / float(points);\n",
    "    x = interval[0];\n",
    "    \n",
    "    for point in range(points):\n",
    "        y = (1/(sigma * math.sqrt(2 * math.pi))) * (math.exp(-1/2 * ( (x - mu)**2 / (sigma)**2 )));\n",
    "        x_data.append(x);\n",
    "        y_data.append(y);\n",
    "        x += step;\n",
    "        \n",
    "    return x_data, y_data\n",
    "\n",
    "# Lets create our data distribution of 60,000 points on the interval mean of 5\n",
    "X_curve, y_curve = createGuassianDistributionPoints(points=100);\n",
    "\n",
    "X = np.array(X_curve);\n",
    "y = np.array(y_curve);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to see the Gaussian\n",
    "def plotCurve(X, y, title=\"Curve\", xlabel=\"Steps\", ylabel=\"Value\", real=False, save=False, save_path=\"\", epoch=0):\n",
    "    x_axis = X\n",
    "    y_axis = y\n",
    "    \n",
    "    if (real):\n",
    "        x_real = X_curve\n",
    "        y_real = y_curve\n",
    "        plt.plot(x_real, y_real, label=\"Expected\")\n",
    "\n",
    "    plt.plot(x_axis, y_axis, label=\"Plotted\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    if (save):\n",
    "        plt.title(\"Training in epoch: \" + str(epoch))\n",
    "        plt.savefig(os.path.join(save_path, str(epoch) + '.png'));\n",
    "    else:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "plotCurve(X_curve, y_curve, title=\"Gaussian Curve\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cf4f9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba8500",
   "metadata": {},
   "source": [
    "Now we want to train a GAN to generate Guassian Distrbutions of our constraints listed earlier. We will make 60,0000 samples (Thats 6,000,000 points to go through!) to have it learn this curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGaussianDataset(\n",
    "    sigma=1, \n",
    "    mu=5,\n",
    "    interval=[0, 10],\n",
    "    points=10,\n",
    "    times=60000\n",
    "):\n",
    "    dataset = [];\n",
    "    \n",
    "    for time in range(times):\n",
    "        X_curve, Y_curve = createGuassianDistributionPoints(\n",
    "            sigma = sigma,\n",
    "            mu = mu,\n",
    "            interval = interval,\n",
    "            points = points\n",
    "        );\n",
    "        dataset.append(Y_curve);\n",
    "    \n",
    "    return np.array(dataset);\n",
    "\n",
    "X_Row = createGaussianDataset(points=100);\n",
    "print(X_Row.shape)\n",
    "print(X_Row);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a074670",
   "metadata": {},
   "source": [
    "# Some Tensor Complications (Matrix in this case as we are not extending our matrix to Tensor even though it is one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d3f17",
   "metadata": {},
   "source": [
    "For Simplicity Sake, we want to train our data in only 2D dimensions so that the its much easier for the data to fit for visualization purposes, thus we must modify our Gaussian Dataset as well.\n",
    "\n",
    "If you recall your linear algebra:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "1 & 2 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If you read column wise, that will be a vector in 2D space.\n",
    "\n",
    "Thus, we want to do the same such that:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_1 & x_2 & \\dots & x_m\\\\\n",
    "y_1 & y_2 & \\dots & y_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Creating a $m \\times 2$ matrix. Using connected layers, we will feed this matrix. The code below is just used to swap so we can see if there is a difference on learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299bd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reshapeColumnMajor(curves):\n",
    "#     \"\"\"\n",
    "#     This is incase we want to swap the m x n matrix\n",
    "#     \"\"\"\n",
    "#     data = [];\n",
    "    \n",
    "#     for curve in curves:\n",
    "#         c = [];\n",
    "        \n",
    "#         for point_index in range(len(curve[0])):\n",
    "#             c.append([\n",
    "#                 curve[0][point_index],\n",
    "#                 curve[1][point_index]\n",
    "#             ]);\n",
    "        \n",
    "#         data.append(c);\n",
    "            \n",
    "#     return np.array(data);\n",
    "\n",
    "# X_Column = reshapeColumnMajor(X_Row);\n",
    "# print(X_Column.shape);\n",
    "# print(X_Column[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77463e77",
   "metadata": {},
   "source": [
    "# GANS Architecture: Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f5d1c",
   "metadata": {},
   "source": [
    "Since our data is purely numerical. We will use dense net (FC) and keras for ease. Its interesting to consider the theory of GAN's, but we will do that after :^)! We will use Tensorflow Library to do this demo!\n",
    "\n",
    "To visualize, we have 60,000 curves. We will have the GAN learning the mapping of each curve to then later learn how to generate Guassian Distributons!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2620e57",
   "metadata": {},
   "source": [
    "### Discriminator Data Sampling Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_real_samples(dataset, n_samples):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------\n",
    "    real_dataset: dataset with the real data\n",
    "    n_samples: amount of real images to sample from\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    X: samples of n images in a list\n",
    "    Y: labels of (1's) for true images (Binary Classification)\n",
    "    \"\"\"\n",
    "    if (isinstance(dataset, list)):\n",
    "        dataset = np.asarray(dataset);\n",
    "        \n",
    "    random_num = randint(0, dataset.shape[0], n_samples);\n",
    "    X = dataset[random_num];\n",
    "    y = np.ones((n_samples, 1));\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c402c",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86310a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleDiscriminator(in_shape=100):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential();\n",
    "    \n",
    "    model.add(Dense(100, input_dim=in_shape, activation='relu')) \n",
    "    model.add(Dense(1, activation='sigmoid')) # Since the decision is binary (Real | Fake), we use sigmoid\n",
    "    \n",
    "    opt = Adam(learning_rate =0.001)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer = opt, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7107a",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf09e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleGenerator(in_shape=100):\n",
    "    model = tf.keras.Sequential();\n",
    "    \n",
    "    model.add(Dense(100, input_dim=in_shape, activation=\"relu\"))\n",
    "    model.add(Dense(100, input_dim=in_shape, activation=\"relu\"))\n",
    "    model.add(Dense(100)) \n",
    "    \n",
    "    return model;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0498d2f",
   "metadata": {},
   "source": [
    "### Summary of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695a540",
   "metadata": {},
   "source": [
    "AIUSDGHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = simpleDiscriminator();\n",
    "generator = simpleGenerator();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca56197",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary();\n",
    "generator.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ac9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c71375",
   "metadata": {},
   "source": [
    "### Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f30905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latentDimensionalGenerator(latent_dimensions, n_samples, randomGaussian = False):\n",
    "    data = [];\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "#         x_input_0 = np.random.choice(X_Row[0][0], latent_dimensions)\n",
    "#         x_input_1 = np.random.choice(X_Row[0][1], latent_dimensions)\n",
    "        x_input_0 = np.random.randn(latent_dimensions); # Points sampled from a normalized distribution.\n",
    "        data.append(x_input_0);\n",
    "#         x_input_1 = np.random.randn(latent_dimensions) + 5; # Points sampled from a normalized distribution.\n",
    "#         data.append([x_input_0, x_input_1]);\n",
    "        \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator production\n",
    "def generate_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = latentDimensionalGenerator(latent_dim, n_samples)  # generate points in a latent space\n",
    "    X = g_model.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))  # create 'fake' class labels (0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad52534",
   "metadata": {},
   "source": [
    "### Visualizing the latent dimensional space in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = latentDimensionalGenerator(100, 10)\n",
    "# print(k)\n",
    "\n",
    "fake_X, fake_y = generate_samples(generator, 100, 10);\n",
    "print(fake_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0007773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotFakeData(fake_data):\n",
    "#     for fake_curve in fake_data:\n",
    "#         plotCurve(fake_curve[0], fake_curve[1]);\n",
    "        \n",
    "# plotFakeData(fake_X);\n",
    "\n",
    "def plotFakeData1D(fake_data, real=False, save=False, save_path=\"\", epoch=0):\n",
    "    for fake_curve in fake_data:\n",
    "        if (real):\n",
    "            plotCurve(X_curve, fake_curve, real=True, save=True, save_path=save_path, epoch=epoch);\n",
    "        else:\n",
    "            plotCurve(X_curve, fake_curve, real = False);\n",
    "        \n",
    "plotFakeData1D(fake_X, real=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35050a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "020c4596",
   "metadata": {},
   "source": [
    "# GAN Architecture: Putting it together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9847cf",
   "metadata": {},
   "source": [
    "aspodkj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False # We set the discriminator as not trainable so the generator updates\n",
    "    model = tf.keras.Sequential() \n",
    "    \n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    opt = Adam(learning_rate = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt) # Generator will train on this loss\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3d15f",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples, save_path=\"\"):\n",
    "    # Real Images based on discriminator\n",
    "    X_real, y_real = sample_real_samples(dataset, n_samples)\n",
    "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "    \n",
    "    # Fake Images based on discriminator\n",
    "    x_fake, y_fake = generate_samples(g_model, latent_dim, n_samples)\n",
    "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "    \n",
    "    print(\"============== CURVE GENERATION ON EPOCH\", epoch,\"==============\");\n",
    "    \n",
    "    if (save_path != \"\"):\n",
    "        plotFakeData1D(x_fake, real=True, save=True, save_path=save_path, epoch=epoch);\n",
    "    else:\n",
    "        plotFakeData1D(x_fake, real=True);\n",
    "    \n",
    "    # summarize discriminator performance\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadec9db",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5327a",
   "metadata": {},
   "source": [
    "asdasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train_gan(g_model, d_model, gan_model, training_data, latent_dim, n_epochs, n_batch, save_path=\"\"):\n",
    "    d1Loss = [];\n",
    "    d2Loss = [];\n",
    "    gLoss = [];\n",
    "    \n",
    "    half_batch = int(n_batch / 2);\n",
    "    \n",
    "    for i in range(n_epochs):                \n",
    "        # Real Image Discriminator Training\n",
    "        X_real, y_real = sample_real_samples(training_data, half_batch)\n",
    "        d_loss1, _ = d_model.train_on_batch(X_real, y_real) # Training on real\n",
    "\n",
    "        # Fake Image Discriminator Training\n",
    "        X_fake, y_fake = generate_samples(g_model, latent_dim, half_batch)\n",
    "        d_loss2, _ = d_model.train_on_batch(X_fake, y_fake) # Training on fakes\n",
    "\n",
    "        # Create a latent space and inverted labels\n",
    "        X_gan = latentDimensionalGenerator(latent_dim, n_batch)\n",
    "        y_gan = np.ones((n_batch, 1)) # Pretend that that they are all real.\n",
    "\n",
    "        # Update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\n",
    "        # summarize loss on this batch\n",
    "        print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "        summarize_performance(i, g_model, d_model, training_data, latent_dim, 1, save_path)\n",
    "        \n",
    "        d1Loss.append(d_loss1);\n",
    "        d2Loss.append(d_loss2);\n",
    "        gLoss.append(g_loss);\n",
    "        \n",
    "    return d1Loss, d2Loss, gLoss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100;\n",
    "gan_model = define_gan(generator, discriminator);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_save_path = \"./images/\"\n",
    "\n",
    "if not os.path.exists(image_save_path):\n",
    "    os.makedirs(image_save_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000;\n",
    "\n",
    "#Training\n",
    "d1, d2, gloss = train_gan(\n",
    "    generator, \n",
    "    discriminator, \n",
    "    gan_model, \n",
    "    X_Row, \n",
    "    latent_dim, \n",
    "    n_epochs, # n_epochs\n",
    "    32,  # batch size\n",
    "    save_path = image_save_path\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(n_epochs + 1));\n",
    "popping = epochs.pop(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCurve(epochs, d1, title=\"d1 loss\");\n",
    "plotCurve(epochs, d2, title=\"d2 loss\");\n",
    "plotCurve(epochs, gloss, title=\"GAN Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad243660",
   "metadata": {},
   "source": [
    "## Some Parameters to keep in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613a14c",
   "metadata": {},
   "source": [
    "Discriminator -> 100 dense (Sigmoid output)\n",
    "Generator -> 100 dense (No activation Output)\n",
    "\n",
    "trained for about 3000 epochs for good convergence on 60,000 of the same Gaussian Curves\n",
    "\n",
    "Discriminator -> \n",
    "100 dense (RELU)\n",
    "(Sigmoid output)\n",
    "\n",
    "Generator -> \n",
    "100 dense (RELU)\n",
    "100 dense (RELU)\n",
    "(No activation Output)\n",
    "\n",
    "trained for about 2000 epochs for good convergence on 60,000 of the same Gaussian Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad65fa",
   "metadata": {},
   "source": [
    "# Save as GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e117ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick n' dirty way of saving to GIF\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "input_folder = \"./images/\"\n",
    "output_folder = './Movie_Data/';\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder);\n",
    "\n",
    "images = []\n",
    "image_name_arr_out = glob.glob(os.path.join(input_folder, \"*.png\")) + glob.glob(os.path.join(input_folder, \"*.tif\")) + glob.glob(os.path.join(input_folder, \"*.jpg\"));\n",
    "\n",
    "for filename in sorted(image_name_arr_out, key = lambda x:x[0:]):\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave(os.path.join(output_folder, \"GAN.gif\"), images);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d859038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
