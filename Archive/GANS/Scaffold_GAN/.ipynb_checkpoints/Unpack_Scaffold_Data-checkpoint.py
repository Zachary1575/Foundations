#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
import cv2
import glob
import shutil

import pandas as pd
import pathlib
import numpy as np
import nibabel as nib
import matplotlib.pyplot as plt
from PIL import Image as ImagePIL


# In[2]:


def renameOp(basename, highest_length_char):
    basename_arr = basename.split(".");
    for x in range(highest_length_char - 1):
        if (len(basename_arr[0]) <= 1):
            basename = "0" + basename;
        
    return basename;


def unpackMainDataset(src_path_root = None, exclusion_file_list = [], doc_count = None, rename=False):
    """
    DFS Implementation of unpacking file directories into a dataset given a root folder.
    """
    data = [];
    file_order = [];
    
    num = 0;
    stack = [];
    visited_contents = [];
    
    stack.append(src_path_root);
    visited_contents.append(src_path_root);
    
    while(len(stack) != 0):
        _curr = stack.pop(len(stack) - 1);
        if (os.path.isdir(_curr)):
            os.chdir(_curr);
            neighbors = sorted(os.listdir());
        
            for n in neighbors:
                path = _curr + "/" + n;
                if (path not in visited_contents):
                    visited_contents.append(path);
                    stack.append(path);
        else:
            filename = os.path.basename(_curr)
            if (filename not in exclusion_file_list):
                num += 1;
                
                if (rename):
                    new_name = renameOp(filename, 2);
                    parent = pathlib.Path(_curr).parent.resolve();
                    os.rename(_curr, (str(parent) + "/" + new_name))
                else:
                    dataframe = pd.read_csv(_curr, skiprows=16);
                    data.append(dataframe);  
                    file_order.append(_curr);
                
    print("DOC COUNT:", num);          
    if (doc_count):
        assert (doc_count == num);
                
    print("Operation Finished.", );
    print();
    return data, file_order;
            
    
# X_Data, file_order = unpackMainDataset(src_path_root, exclusion_file_list=["Print log.pptx", "~$Print log.pptx", ".DS_Store", "0.DS_Store", "modulus_data.csv", "modulus_data_types.csv"], rename=False);


# In[3]:


def unpackProcessingParameters(src_root_path):
    dataframe = pd.read_csv(src_root_path);
    numpy_df = dataframe.to_numpy();
    print(dataframe)
    print("Operation Finished.")
    print();
    return dataframe, numpy_df;
    
# parameters_df, parameters_np = unpackProcessingParameters(src_root_path);


# In[4]:


# Pad the data
def rowNormalization(X_Data):
    max_row = -1;
    
    data = [];
    for dataframe in X_Data:
        row_len = len(dataframe.index);
        
        if (row_len > max_row):
            max_row = row_len;

    for dataframe in X_Data:
        padDF = dataframe.reindex(range(max_row), fill_value=0)
        data.append(padDF);
        
    data = np.array(data);
    return data;

# X_Data_N = rowNormalization(X_Data);


# In[5]:


# Sanity Check
# print(X_Data_N.shape);


# In[6]:


# Transpose all the data for it to be easier
def transposeData(X_Data):
    X = [];
    
    for data in X_Data:
        X.append(data.T);
        
    return np.array(X);

# X_Data_N_T = transposeData(X_Data_N);
# parameters_np_T = transposeData(parameters_np);

# print(X_Data_N_T.shape);
# print(parameters_np_T.shape);


# # Calculation of Porosity, Energy Absorpotion, and Compression Modulus

# Let $g_{const}$ = gripping distance = $10mm$
# 
# Let $a_{const}$ = cross section area = $100mm^2$
# 
# Let $b_{const}$ = block weight
# 
# Let $s_{const}$ = scaffold weight
# 
# Let $\Delta D$ = displacement
# 
# Let $\alpha$ = Force Generated by Compression (N)
# 
# Porosity = $1 - \left(\dfrac{s_{const}}{b_{const}}\right)$
# 
# Stress = $\dfrac{\alpha}{a_{const} * 10^{-6}}$
# 
# Strain = $\dfrac{\Delta D}{g_{const}}$
# 
# Energy absorption = Area under the Stress-Strain Curve
# 
# Compression Modulus = Slope until Climax

# In[7]:


# Assumes Compression test
# Assumes Block heights to be in mm
def stressStrainCurveConversion(X, blockHeight):
    data = [];
    
    for experiment_index in range(len(X)):
        experiment = X[experiment_index];
        prev_strain = 0; # Keep the previous strain
        
        for point_index in range(len(experiment[0])):
            time = experiment[0][point_index];
            force = experiment[1][point_index];
            displacement = experiment[2][point_index];
            
            stress = (float(force) / float(100)); # megaPascals (mPA)
            strain = (float(displacement) / float(10)) * 100; # Percentage
            
            if (displacement == 0.0 and force == 0.0 and time == 0.0):
                strain = prev_strain;
            
            prev_strain = strain
            experiment[0][point_index] = strain; 
            experiment[1][point_index] = stress;
            
        data.append(experiment[:2, :]);
            
    return np.array(data);
            
            
# stressStrain_X = stressStrainCurveConversion(X_Data_N_T, 10)
# print(stressStrain_X.shape)


# In[8]:


#f_parameters_np = np.flip(parameters_np, 0); # Flip it because the order starts from Print 45, 15.csv


# # Actual functions to be exported and used

# In[11]:


# curve_path = "/Users/zacharyg/Documents/GitHub/fundemental-neural-nets/GANS/Scaffold_GAN/scaffold_dataset_WU_LAB/Prints"
# modulus_path = "/Users/zacharyg/Documents/GitHub/fundemental-neural-nets/GANS/Scaffold_GAN/scaffold_dataset_WU_LAB/Prints/modulus_data_types.csv"

def readAndOutputDataset(src_curve_path, src_modulus_path, reverse=False):
    X_Data, file_order = unpackMainDataset( # Get the Curve Data
        src_curve_path, 
        exclusion_file_list=[
            "Print log.pptx", 
            "~$Print log.pptx", 
            ".DS_Store", 
            "0.DS_Store", 
            "modulus_data.csv", 
            "modulus_data_types.csv"
        ], 
        rename=False
        );
    
    parameters_df, parameters_np = unpackProcessingParameters(src_modulus_path); # Get the processing parameters data
    X_Data_N = rowNormalization(X_Data);
    X_Data_N_T = transposeData(X_Data_N); # Transpose to be column major
    
    X_stressStrain = stressStrainCurveConversion(X_Data_N_T, 10); # calculation to stress-strain curve
    
    if (reverse):
        parameters_np = np.flip(parameters_np, 0); # Flip it because the order starts from Print 45, 15.csv
        pass
    
    return X_stressStrain, parameters_np, parameters_df, file_order 


# X, y, y_df, file_order = readAndOutputDataset(curve_path, modulus_path, reverse=True);


# In[12]:


def curveVisualization(X_StressStrain, parameters_np, file_order):
    # Graphing of Stress Strain Curves
    for curve_index in range(len(X_StressStrain)):
        curve = X_StressStrain[curve_index];
        x_axis = curve[0]; # Strain (%)
        y_axis = curve[1]; # Stress (mPA)

        print("FILE: ", file_order[curve_index]);
        plt.plot(x_axis, y_axis)
        plt.title('Stress-Strain Graph')
        plt.xlabel('Strain (%)')
        plt.ylabel('Stress(mPa)')
        plt.show()
        
        print("MODULUS:", parameters_np[curve_index][1]);
        print("SPACING:", parameters_np[curve_index][2]);
        print("INFILL:", parameters_np[curve_index][3]);
        print("HEIGHT:", parameters_np[curve_index][4]);
        print("SPEED:", parameters_np[curve_index][5]);
        print("TEMPERATURE:", parameters_np[curve_index][6]);
        print("MASS:", parameters_np[curve_index][7]);
        print("POROSITY:", parameters_np[curve_index][8]);
        print("TYPE:", parameters_np[curve_index][9]);
        print();
        print();
    
    return;


# curveVisualization(X, y, file_order);


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:




