{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Funcs\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as ImagePIL\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb46352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Reshape\n",
    "from keras import backend\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29690b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Funcs\n",
    "from Unpack_Scaffold_Data import readAndOutputDataset, curveVisualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b1e02",
   "metadata": {},
   "source": [
    "# Data Read Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_path = \"/Users/zacharyg/Documents/GitHub/fundemental-neural-nets/GANS/Scaffold_GAN/scaffold_dataset_WU_LAB/Prints\"\n",
    "modulus_path = \"/Users/zacharyg/Documents/GitHub/fundemental-neural-nets/GANS/Scaffold_GAN/scaffold_dataset_WU_LAB/Prints/modulus_data_types.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_df, file_order = readAndOutputDataset(curve_path, modulus_path, reverse=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0820807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "print(\"X SHAPE:\", X.shape);\n",
    "print(\"y SHAPE:\", y.shape);\n",
    "print();\n",
    "\n",
    "\n",
    "# Visualization\n",
    "# curveVisualization(X, y, file_order);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969328b",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d855d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposeStressData(X_Data):\n",
    "    X = [];\n",
    "    \n",
    "    for data in X_Data:\n",
    "        X.append(data.T);\n",
    "        \n",
    "    return np.array(X);\n",
    "\n",
    "def normalizeStressStrain(x):\n",
    "    for curve_index in range(len(x)):\n",
    "        curve = x[curve_index];\n",
    "        \n",
    "        max_stress_val = np.max(curve[0]);\n",
    "        max_strain_val = np.max(curve[1]);\n",
    "        \n",
    "        curve[0] = curve[0] / max_stress_val;\n",
    "        curve[1] = curve[1] / max_strain_val;\n",
    "        \n",
    "    return x;\n",
    "\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    \n",
    "    Parameters\n",
    "    -----------------\n",
    "    x: Array of Homogenous (RGB) values of input data \n",
    "    \n",
    "    Returns\n",
    "    -----------------\n",
    "    new_imgs: (numpy integer array) Numpy array of normalized data\n",
    "    \"\"\"\n",
    "    return np.array((x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "def stringtoCategorical(y):    \n",
    "    data = [];\n",
    "    \n",
    "    for type_index in range(len(y)):\n",
    "        wrd = y[type_index];\n",
    "        encoding = 0.0;\n",
    "        \n",
    "        if (wrd == \"Cubic\"):\n",
    "            encoding = 1.0;\n",
    "        elif (wrd == \"Gyroid\"):\n",
    "            encoding = 2.0;\n",
    "            \n",
    "        data.append([encoding]);\n",
    "        \n",
    "    return np.array(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09112fe",
   "metadata": {},
   "source": [
    "# Process Parameter Stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ca35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameterStrip(y):\n",
    "    y_t = y.T;\n",
    "    \n",
    "    Index = y_t[0];\n",
    "    Modulus = y_t[1];\n",
    "    Spacing = y_t[2];\n",
    "    Infill = y_t[3];\n",
    "    Height = y_t[4];\n",
    "    Speed = y_t[5];\n",
    "    Temp = y_t[6];\n",
    "    Mass = y_t[7];\n",
    "    Porosity = y_t[8];\n",
    "    Type = y_t[9];\n",
    "    return Index, Modulus, Spacing, Infill, Height, Speed, Temp, Mass, Porosity, Type\n",
    "\n",
    "Index, Modulus, Spacing, Infill, Height, Speed, Temp, Mass, Porosity, Type = parameterStrip(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609460a8",
   "metadata": {},
   "source": [
    "# Stress String Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d7168",
   "metadata": {},
   "source": [
    "X_Data -> 675 Stress Strain Curves\n",
    "\n",
    "Features that is calculated from the Curve:\n",
    "* Energy Absorption (No calculation yet...)\n",
    "* Compression Modulus\n",
    "* Porosity\n",
    "\n",
    "Printing Parameters:\n",
    "* Infill Pattern (1-3)\n",
    "* Line Distance\n",
    "* Weight\n",
    "* Print Speed\n",
    "* Layer Height\n",
    "* Print Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e0621",
   "metadata": {},
   "source": [
    "Perhaps we can try to represent these things with an image. We have a table:\n",
    "\n",
    "Let $x_n \\in \\{(R, G, B)\\}$, where $R,G,B \\in \\mathbb{R}$\n",
    "\n",
    "|             | $P_1$   | $P_2$   | $P_3$   | $P_4$   | $\\dots$ | \n",
    "| ----------- | ------- | ------- | ------- | ------- | ------- |\n",
    "| $c_1$       |  $x_1$  |  $x_2$  |  $x_3$  |  $x_4$  |  $x_5$  |\n",
    "| $c_2$       |  $x_6$  |  $x_7$  |  $x_8$  |  $x_9$  |$\\vdots$ |\n",
    "| $\\vdots$     |  $x_{11}$|  $x_{12}$  |  $x_{13}$  |  $\\dots$  |$x_{k}$ |\n",
    "\n",
    "\n",
    "So by designing a $m \\times n$ matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_1 & x_2 & \\dots & x_m\\\\\n",
    "y_1 & y_2 & \\dots & y_m\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSimpleScatter(X, y, title=\"Curve\", xlabel=\"Steps\", ylabel=\"Value\", size=20):\n",
    "    x_axis = X\n",
    "    y_axis = y\n",
    "\n",
    "    plt.scatter(x_axis, y_axis, s=size)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plotPlotlyScatter(X, y):\n",
    "    fig = px.scatter(x=X, y=y)\n",
    "    fig.show()\n",
    "\n",
    "stress_strain_domain = list(range(675 + 1));\n",
    "stress_strain_domain.pop(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a833bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Modulus Max:\", np.max(Modulus));\n",
    "print(\"Porosity Max:\", np.max(Porosity));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f3a8b",
   "metadata": {},
   "source": [
    "### Spearman Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63fa60",
   "metadata": {},
   "source": [
    "Spearman’s rank correlation coefficient, denoted by $r_s$, is a numerical value such that $-1 \\leq 1 \\leq 1$. It gives a measure of the likelihood of one variable increasing as the other increases (a direct association) or of one variable decreasing as the other increases (an inverse association). Direct associations are indicated by positive values, and inverse associations are indicated by negative values. No association is indicated by a value of $0$. The stronger the association, the closer $r_s$ is to $−1$ or $1$, and the weaker the association, the closer it is to $0$. Rank correlation coefficient values of $1$ or $−1$ mean that either the ranks agree entirely $(r_s = 1)$ or they are direct opposites $(r_s = -1)$.\n",
    "\n",
    "The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables; while Pearson's correlation assesses linear relationships, Spearman's correlation assesses monotonic relationships (whether linear or not). If there are no repeated data values, a perfect Spearman correlation of +1 or −1 occurs when each of the variables is a perfect monotone function of the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameter_Sum = [];\n",
    "\n",
    "for index in range(len(Spacing)):\n",
    "    Summation = Spacing[index] + Infill[index] + Height[index] + Speed[index] + Temp[index];\n",
    "    Parameter_Sum.append(Summation);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2eb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cf648a2",
   "metadata": {},
   "source": [
    "# Simple 1D CGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f45c87",
   "metadata": {},
   "source": [
    "### Looking at Overall Feature Data Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7870c9",
   "metadata": {},
   "source": [
    "Let $D$ be a set of sets such that $|D| = 675$. Let $d_1, d_2, ..., d_n \\in D$ be the set within sets. Printing scalar values that are set during the printing process. Suppose that $C$ and $P$ denote curve parameters and printing parameters respectively.\n",
    "\n",
    "We denote that $d_n = \\{C_1, P_1, P_2, P_3, P_4, P_5, C_2, C_3\\}$ be denoted as **Compression Modulus, Spacing, Infill Type, Height, Speed, Temperature, Weight, and Porosity** resepectively, where  $C_1, P_1, P_2, P_3, P_4, P_5, C_2, C_3 \\geq 0$.\n",
    "\n",
    "An additional parameter to note, for **Infill Type**, the values are fixed discretely such that:\n",
    "\n",
    " $$Infill \\ Type(P_2) = \\begin{cases}\n",
    "  0  & P_2 \\text{ is Line} \\\\\n",
    "  1  & P_2 \\text{ is Cubic} \\\\\n",
    "  2  & P_2 \\text{ is Gyroid}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab792e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 675 Stress-Strain Curve Domain\n",
    "feature_domain_675 = list(range(675 + 1));\n",
    "feature_domain_675.pop(0) \n",
    "feature_domain_675 = np.repeat(feature_domain_675, 7, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041c378",
   "metadata": {},
   "source": [
    "### Parameter Cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "\n",
    "cut_params_1 = y[:, 1:3]; # Drop Infill Type\n",
    "cut_params_2 = y[:, 4:9]; # Drop Infill Type\n",
    "cut_params = np.concatenate((cut_params_1, cut_params_2), axis=1);\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "_cut_params = cut_params; # Copy it\n",
    "cut_params = cut_params.flatten();\n",
    "\n",
    "print(_cut_params);\n",
    "\n",
    "print();\n",
    "print()\n",
    "\n",
    "print(cut_params); # Unravel Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    x=feature_domain_675, \n",
    "    y=cut_params,\n",
    "    title=\"Each point of dataset over 675 curves\",\n",
    "    labels = {\"x\": \"Parameters\", \"y\": \"Values\"}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "cut_params_N = [];\n",
    "max_value = np.max(_cut_params);\n",
    "\n",
    "print(\"The Max value is:\", max_value);\n",
    "\n",
    "for curve in _cut_params:\n",
    "    cut_params_N.append(curve / max_value);\n",
    "    \n",
    "cut_params_N = np.array(cut_params_N);\n",
    "\n",
    "cut_params_N_Flatten = cut_params_N.flatten();\n",
    "\n",
    "# Just as a sanity check...\n",
    "fig = px.scatter(\n",
    "    x=feature_domain_675, \n",
    "    y=cut_params_N_Flatten,\n",
    "    title=\"Each point of dataset over 675 curves\",\n",
    "    labels = {\"x\": \"Parameters\", \"y\": \"Values\"}\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066fe447",
   "metadata": {},
   "source": [
    "### Looking at each parameter distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_domain_7 = list(range(7 + 1));\n",
    "feature_domain_7.pop(0);\n",
    "\n",
    "feature_domain_7_rep = list(np.arange(1,8))*675\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=feature_domain_7, \n",
    "    y=cut_params_N[0],\n",
    "    title=\"Parameters of Curve 1\",\n",
    "    labels = {\"x\": \"Parameters\", \"y\": \"Values\"}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# View ALL (FULL DISTRIBUTION)\n",
    "fig = px.scatter(\n",
    "    x=feature_domain_7_rep, \n",
    "    y=cut_params,\n",
    "    title=\"Parameters of All Curves\",\n",
    "    labels = {\"x\": \"Parameters\", \"y\": \"Values\"}\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Lines Chart (DISTRIBUTION)\n",
    "fig_k = px.line(\n",
    "    x=feature_domain_7, \n",
    "    y=cut_params_N[200],\n",
    "    title=\"Single Parameter Curve\",\n",
    "    labels={\"x\": \"Parameters\", \"y\":\"Normalized values (Divided by Max)\"}\n",
    ")\n",
    "\n",
    "fig_k.show()\n",
    "\n",
    "\n",
    "# Multiple Lines Chart (DISTRIBUTION)\n",
    "fig = go.Figure()\n",
    "\n",
    "for line in range(len(cut_params_N)):\n",
    "    data = cut_params_N[line];\n",
    "    fig.add_trace(go.Scatter(x=feature_domain_7, y=data))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bcf145",
   "metadata": {},
   "source": [
    "### One Hot Encode the Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneCategorical(y):\n",
    "    arr = [];\n",
    "    for data in y:\n",
    "        if (data == 1):\n",
    "            arr.append([0.0]);\n",
    "        elif (data == 2):\n",
    "            arr.append([1.0]);\n",
    "        elif (data == 3):\n",
    "            arr.append([2.0]);\n",
    "    \n",
    "    return np.array(arr);\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebf3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encoded_infill_types = tf.keras.utils.to_categorical((Infill - 1), num_classes = 3);\n",
    "print(hot_encoded_infill_types.shape);\n",
    "# print()\n",
    "# print(hot_encoded_infill_types[0].shape);\n",
    "# print()\n",
    "# print(hot_encoded_infill_types);\n",
    "\n",
    "hot_encoded_infill_types_one_dimensional = oneCategorical(Infill);\n",
    "\n",
    "print(hot_encoded_infill_types_one_dimensional.shape)\n",
    "# print()\n",
    "# print(hot_encoded_infill_types_one_dimensional);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d1bbfe",
   "metadata": {},
   "source": [
    "### Pairwise Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [];\n",
    "\n",
    "for param_index in range(len(cut_params_N)):\n",
    "    data = cut_params_N[param_index]\n",
    "    category = hot_encoded_infill_types_one_dimensional[param_index]\n",
    "    payload = [data, category]\n",
    "    X.append(payload);\n",
    "    \n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3e118",
   "metadata": {},
   "source": [
    "### Discriminator Data Sampling Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e226c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_real_samples(dataset, n_samples):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------\n",
    "    dataset: dataset with the real data\n",
    "    cond_data: the data that is conditioned with the GAN\n",
    "    n_samples: amount of real images to sample from\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    X: samples of n images in a list\n",
    "    Y: labels of (1's) for true images (Binary Classification)\n",
    "    \"\"\"\n",
    "    params = [];\n",
    "    labels = [];\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        randVal = random.choice(dataset)\n",
    "        params.append(randVal[0].astype('float32'));\n",
    "        labels.append(randVal[1].astype('float32'));\n",
    "    y = np.ones((n_samples, 1));\n",
    "    \n",
    "    return [params, labels], y\n",
    "\n",
    "[P, O], B = sample_real_samples(X, 10)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c414b15",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4093b",
   "metadata": {},
   "source": [
    "Remember that the Objective Function this time is:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\min_{G}\\max_{D}V(D,G) = \\mathbb{E}_{x \\text{-} p_{data}(x)}[\\log D(x | y)]\n",
    "+ \\mathbb{E}_{z \\text{-} p_{z}(z)} [\\log (1 - D(G(z | y))]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Such that $y$ is a auxillary data. In this case, its the infill type (One hot encoded) which helps better learn the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionalDiscriminator(in_shape=7, num_classes=3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    in_label = tf.keras.Input(shape=(1,))\n",
    "    embed = tf.keras.layers.Embedding(num_classes, 10)(in_label) # Keep the embedding layers low...\n",
    "    cond_y = tf.keras.layers.Dense(7)(embed)\n",
    "    cond_y = tf.keras.layers.Reshape((7,))(cond_y)\n",
    "    \n",
    "    in_parameters = tf.keras.Input(shape=in_shape)\n",
    "    merge = tf.keras.layers.Concatenate()([in_parameters, cond_y])\n",
    "    x = tf.keras.layers.Dense(7, input_dim=in_shape, activation='relu')(merge)\n",
    "    x = tf.keras.layers.Dense(7, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(7, activation='relu')(x)\n",
    "    out = tf.keras.layers.Dense(1, activation='sigmoid')(x) # Output layer\n",
    "    \n",
    "    model = tf.keras.Model([in_parameters, in_label], out)\n",
    "    \n",
    "    opt = Adam(learning_rate =0.001)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer = opt, \n",
    "        metrics=['accuracy']\n",
    "    );\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c788e",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionalGenerator(in_shape=7, num_classes=3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    in_label = tf.keras.Input(shape=(1,))\n",
    "    embed = tf.keras.layers.Embedding(num_classes, 10)(in_label) # Keep the embedding layers low...\n",
    "    cond_y = tf.keras.layers.Dense(7)(embed)\n",
    "    cond_y = tf.keras.layers.Reshape((7,))(cond_y)\n",
    "    \n",
    "    in_noise = tf.keras.Input(shape=in_shape)\n",
    "    merge = tf.keras.layers.Concatenate()([in_noise, cond_y])\n",
    "    x = tf.keras.layers.Dense(100, activation='relu')(merge)\n",
    "    x = tf.keras.layers.Dense(7, activation='relu')(x)\n",
    "    out = tf.keras.layers.Dense(7, input_dim=in_shape)(x)\n",
    "    \n",
    "    model = tf.keras.Model([in_noise, in_label], out)\n",
    "    \n",
    "    return model;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1229c48",
   "metadata": {},
   "source": [
    "### Summary of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221331a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = conditionalDiscriminator();\n",
    "generator = conditionalGenerator(7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f97bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary();\n",
    "generator.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649ffd6",
   "metadata": {},
   "source": [
    "### Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latentDimensionalGenerator(latent_dimensions, n_samples, randomGaussian = False):\n",
    "    data = [];\n",
    "    y_cond_data = [];\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        x_input_0 = np.random.randn(latent_dimensions); # Points sampled from a normalized distribution.\n",
    "        data.append(x_input_0);\n",
    "        y_cond_data.append([float(random.randint(0, 2))])\n",
    "        \n",
    "    return np.array(data), np.array(y_cond_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator production\n",
    "def generate_samples(g_model, latent_dim, n_samples):\n",
    "    x_input, y_cond = latentDimensionalGenerator(latent_dim, n_samples)  # generate points in a latent space\n",
    "    X = g_model.predict([x_input, y_cond])\n",
    "    y = np.zeros((n_samples, 1))  # create 'fake' class labels (0)\n",
    "    return [X, y_cond], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3057b48",
   "metadata": {},
   "source": [
    "### Visualizing the latent dimensional space in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = latentDimensionalGenerator(7, 10)\n",
    "# print(k)\n",
    "\n",
    "fake_X, fake_y = generate_samples(generator, 7, 10);\n",
    "print(len(fake_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb6aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for curve in fake_X[0]:\n",
    "    fig = go.Figure();\n",
    "    fig.add_trace(go.Scatter(x=feature_domain_7, y=curve));\n",
    "    fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9aa79",
   "metadata": {},
   "source": [
    "### GAN: Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697eeff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False # We set the discriminator as not trainable so the generator updates\n",
    "\n",
    "    z, y_label = generator.input\n",
    "    \n",
    "    gen_output = generator.output\n",
    "    gan_output = discriminator([gen_output, y_label])\n",
    "    \n",
    "    model = tf.keras.Model([z, y_label], gan_output)\n",
    "    \n",
    "    opt = Adam(learning_rate = 0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0536270",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a71893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples, save_path=\"\"):\n",
    "    # Real Images based on discriminator\n",
    "    [X_real, real_labels], y_real = sample_real_samples(dataset, n_samples)\n",
    "    _, acc_real = d_model.evaluate([tf.stack(X_real), tf.stack(real_labels)], y_real, verbose=0)\n",
    "    \n",
    "    # Fake Images based on discriminator\n",
    "    [X_fake, labels], y_fake = generate_samples(g_model, latent_dim, n_samples)\n",
    "    _, acc_fake = d_model.evaluate([tf.stack(X_fake), tf.stack(labels)], y_fake, verbose=0)\n",
    "    \n",
    "    print(\"============== CURVE GENERATION ON EPOCH\", epoch,\"==============\");\n",
    "    \n",
    "    for curve in X_fake:\n",
    "        plt.plot(feature_domain_7, curve)\n",
    "    \n",
    "    if (save_path != \"\"):\n",
    "        plt.title(\"Training in epoch: \" + str(epoch))\n",
    "        plt.savefig(os.path.join(save_path, str(epoch) + '.png'));\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    # summarize discriminator performance\n",
    "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5442b93",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train_gan(g_model, d_model, gan_model, training_data, latent_dim, n_epochs, n_batch, save_path=\"\"):\n",
    "    d1Loss = [];\n",
    "    d2Loss = [];\n",
    "    gLoss = [];\n",
    "    \n",
    "    half_batch = int(n_batch / 2);\n",
    "    \n",
    "    for i in range(n_epochs):                \n",
    "        # Real Image Discriminator Training\n",
    "        [X_real, real_labels], y_real = sample_real_samples(training_data, half_batch) # Note X_Real is [data, labels]\n",
    "        d_loss1, _ = d_model.train_on_batch([tf.stack(X_real), tf.stack(real_labels)], y_real) # Training on real\n",
    "\n",
    "        # Fake Image Discriminator Training\n",
    "        [X_fake, labels], y_fake = generate_samples(g_model, latent_dim, half_batch)\n",
    "        d_loss2, _ = d_model.train_on_batch([tf.stack(X_fake), tf.stack(labels)], y_fake) # Training on fakes\n",
    "\n",
    "        # Create a latent space and inverted labels\n",
    "        noise_z, labels = latentDimensionalGenerator(latent_dim, n_batch) # Latent space generation\n",
    "        y_gan = np.ones((n_batch, 1)) # Pretend that that they are all real.\n",
    "\n",
    "        # Update the generator via the discriminator's error\n",
    "        g_loss = gan_model.train_on_batch([tf.stack(noise_z), tf.stack(labels)], y_gan)\n",
    "\n",
    "        # summarize loss on this batch\n",
    "        print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "        summarize_performance(i, g_model, d_model, training_data, latent_dim, 100, save_path)\n",
    "        \n",
    "        d1Loss.append(d_loss1);\n",
    "        d2Loss.append(d_loss2);\n",
    "        gLoss.append(g_loss);\n",
    "        \n",
    "    return d1Loss, d2Loss, gLoss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 7;\n",
    "gan_model = define_gan(generator, discriminator);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef96f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getcwd());\n",
    "# os.chdir(\"/Users/zacharyg/Documents/GitHub/fundemental-neural-nets/GANS/Scaffold_GAN\");\n",
    "# image_save_path = \"./images/\"\n",
    "\n",
    "# if not os.path.exists(image_save_path):\n",
    "#     os.makedirs(image_save_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000;\n",
    "# X = cut_params_N.astype('float32')\n",
    "\n",
    "#Training\n",
    "d1, d2, gloss = train_gan(\n",
    "    generator, \n",
    "    discriminator, \n",
    "    gan_model, \n",
    "    X, \n",
    "    latent_dim, \n",
    "    n_epochs, # n_epochs\n",
    "    20,  # batch size\n",
    "#     save_path = image_save_path\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01533b",
   "metadata": {},
   "source": [
    " Try #1 -> A Good convergence is like 6000 epochs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCurve(X, y, title=\"Curve\", xlabel=\"Steps\", ylabel=\"Value\"):\n",
    "    x_axis = X\n",
    "    y_axis = y\n",
    "\n",
    "    plt.plot(x_axis, y_axis)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(n_epochs + 1));\n",
    "popping = epochs.pop(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddfb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCurve(epochs, d1, title=\"d1 loss\");\n",
    "plotCurve(epochs, d2, title=\"d2 loss\");\n",
    "plotCurve(epochs, gloss, title=\"GAN Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1eb44f",
   "metadata": {},
   "source": [
    "# Save GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick n' dirty way of saving to GIF\n",
    "# import imageio.v2 as imageio\n",
    "\n",
    "# input_folder = \"./images/\"\n",
    "# output_folder = './Movie_Data/';\n",
    "\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder);\n",
    "\n",
    "# images = []\n",
    "# image_name_arr_out = glob.glob(os.path.join(input_folder, \"*.png\")) + glob.glob(os.path.join(input_folder, \"*.tif\")) + glob.glob(os.path.join(input_folder, \"*.jpg\"));\n",
    "\n",
    "# for filename in sorted(image_name_arr_out, key = lambda x:x[0:]):\n",
    "#     images.append(imageio.imread(filename))\n",
    "# imageio.mimsave(os.path.join(output_folder, \"GAN.gif\"), images);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5983a",
   "metadata": {},
   "source": [
    "# Prediction Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[fake_X, fake_label], fake_y = generate_samples(generator, 7, 100);\n",
    "\n",
    "for label_index in range(len(fake_X)):\n",
    "    label = fake_label[label_index];\n",
    "    parameters = fake_X[label_index] * max_value;\n",
    "    \n",
    "    print(\"Label:\", label)\n",
    "    print(\"Data:\", parameters)\n",
    "    print()\n",
    "    \n",
    "print(y[150]);\n",
    "    \n",
    "# # Single Lines Chart (DISTRIBUTION)\n",
    "# fig_k = px.line(\n",
    "#     x=feature_domain_8, \n",
    "#     y=fake_X[99] * max_value,\n",
    "#     title=\"Single Parameter Curve\",\n",
    "#     labels={\"x\": \"Parameters\", \"y\":\"Normalized values (Divided by Max)\"}\n",
    "# )\n",
    "\n",
    "# fig_k.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cut_params_N[199])\n",
    "print();\n",
    "print(cut_params_N[199] * max_value)\n",
    "\n",
    "# Single Lines Chart (DISTRIBUTION)\n",
    "fig_k = px.line(\n",
    "    x=feature_domain_8, \n",
    "    y=cut_params_N[199] * max_value,\n",
    "    title=\"Single Parameter Curve\",\n",
    "    labels={\"x\": \"Parameters\", \"y\":\"Normalized values (Divided by Max)\"}\n",
    ")\n",
    "\n",
    "fig_k.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42acdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
